{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline, PipelineModel\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "import sparknlp\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp.common import *\n",
    "from sparknlp.base import *\n",
    "from sparknlp.training import CoNLL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start(gpu=False):\n",
    "    builder = SparkSession.builder \\\n",
    "        .appName(\"Spark NLP - NERDL training\") \\\n",
    "        .master(\"local[*]\") \\\n",
    "        .config(\"spark.driver.memory\", \"10G\") \\\n",
    "        .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\")\\\n",
    "        .config(\"spark.kryoserializer.buffer.max\", \"1000M\")\n",
    "    if gpu:\n",
    "        builder.config(\"spark.jars.packages\", \"com.johnsnowlabs.nlp:spark-nlp-gpu_2.11:2.4.3\")\n",
    "    else:\n",
    "        builder.config(\"spark.jars.packages\", \"com.johnsnowlabs.nlp:spark-nlp_2.11:2.4.3\")\n",
    "\n",
    "    return builder.getOrCreate()\n",
    "  \n",
    "spark = start(gpu=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark NLP version:  2.5.3\n",
      "Apache Spark version:  2.4.5\n"
     ]
    }
   ],
   "source": [
    "print(\"Spark NLP version: \", sparknlp.version())\n",
    "print(\"Apache Spark version: \", spark.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read CoNLL train file\n",
    "training_data = CoNLL().readDataset(spark, '/home/francesco/clinical_ner/conll.train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16311"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read CoNLL test file\n",
    "test_data = CoNLL().readDataset(spark, '/home/francesco/clinical_ner/conll.test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27568"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the trained embeddings model\n",
    "BioVec_embeddings = WordEmbeddingsModel.load('./embeddings/BioVec_model')\\\n",
    "        .setInputCols(['sentence', 'token'])\\\n",
    "        .setOutputCol('biowordvec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_bio = BioVec_embeddings.transform(test_data)\n",
    "test_data_bio.write.parquet(\"test_withBioVecEmbeds.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nerTagger = NerDLApproach()\\\n",
    ".setInputCols(['sentence', 'token', 'biowordvec'])\\\n",
    ".setLabelColumn('label')\\\n",
    ".setOutputCol('ner')\\\n",
    ".setMaxEpochs(20)\\\n",
    ".setLr(0.001)\\\n",
    ".setPo(0.005)\\\n",
    ".setBatchSize(8)\\\n",
    ".setRandomSeed(0)\\\n",
    ".setVerbose(2)\\\n",
    ".setEvaluationLogExtended(True)\\\n",
    ".setEnableOutputLogs(True)\\\n",
    ".setIncludeConfidence(True)\\\n",
    ".setTestDataset('test_withBioVecEmbeds.parquet')\\\n",
    ".setGraphFolder('/home/francesco/graph/tensorflow_graph')\n",
    "\n",
    "pipeline = Pipeline( stages = [\n",
    "                BioVec_embeddings,\n",
    "                nerTagger\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_model = pipeline.fit(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|            text|            document|            sentence|               token|                 pos|               label|          biowordvec|                 ner|\n",
      "+----------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|admission date :|[[document, 0, 15...|[[document, 0, 15...|[[token, 0, 8, ad...|[[pos, 0, 8, NN, ...|[[named_entity, 0...|[[word_embeddings...|[[named_entity, 0...|\n",
      "|      2012-10-31|[[document, 0, 9,...|[[document, 0, 9,...|[[token, 0, 9, 20...|[[pos, 0, 9, NN, ...|[[named_entity, 0...|[[word_embeddings...|[[named_entity, 0...|\n",
      "|discharge date :|[[document, 0, 15...|[[document, 0, 15...|[[token, 0, 8, di...|[[pos, 0, 8, NN, ...|[[named_entity, 0...|[[word_embeddings...|[[named_entity, 0...|\n",
      "+----------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = ner_model.transform(test_data)\n",
    "predictions.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+------------+-----------+\n",
      "|token                   |ground_truth|prediction |\n",
      "+------------------------+------------+-----------+\n",
      "|admission               |O           |O          |\n",
      "|date                    |O           |O          |\n",
      "|:                       |O           |O          |\n",
      "|2012-10-31              |O           |O          |\n",
      "|discharge               |O           |O          |\n",
      "|date                    |O           |O          |\n",
      "|:                       |O           |O          |\n",
      "|2012-11-07              |O           |O          |\n",
      "|date                    |O           |O          |\n",
      "|of                      |O           |O          |\n",
      "|birth                   |O           |O          |\n",
      "|:                       |O           |O          |\n",
      "|1941-03-23              |O           |O          |\n",
      "|sex                     |O           |O          |\n",
      "|:                       |O           |O          |\n",
      "|m                       |O           |O          |\n",
      "|service                 |O           |O          |\n",
      "|:                       |O           |O          |\n",
      "|medicine                |O           |O          |\n",
      "|allergies               |O           |O          |\n",
      "|:                       |O           |O          |\n",
      "|nsaids/anti-inflammatory|B-treatment |O          |\n",
      "|classifier              |I-treatment |O          |\n",
      "|/                       |O           |O          |\n",
      "|vancomycin              |B-treatment |B-treatment|\n",
      "|attending               |O           |O          |\n",
      "|:                       |O           |O          |\n",
      "|kristie                 |O           |O          |\n",
      "|r                       |O           |O          |\n",
      "|hamby                   |O           |O          |\n",
      "|,                       |O           |O          |\n",
      "|md                      |O           |O          |\n",
      "|chief                   |O           |O          |\n",
      "|complaint               |O           |O          |\n",
      "|:                       |O           |O          |\n",
      "|cc                      |O           |O          |\n",
      "|:                       |O           |O          |\n",
      "|antonio                 |O           |O          |\n",
      "|m                       |O           |O          |\n",
      "|z                       |O           |O          |\n",
      "|eddings                 |O           |O          |\n",
      "|,                       |O           |O          |\n",
      "|md                      |O           |O          |\n",
      "|major                   |O           |O          |\n",
      "|surgical                |O           |O          |\n",
      "|or                      |O           |O          |\n",
      "|invasive                |O           |O          |\n",
      "|procedure               |O           |O          |\n",
      "|:                       |O           |O          |\n",
      "|mesenteric              |B-test      |B-test     |\n",
      "|angiograpm              |I-test      |I-test     |\n",
      "|w/                      |O           |O          |\n",
      "|coil                    |B-treatment |B-treatment|\n",
      "|embolization            |I-treatment |I-treatment|\n",
      "|of                      |O           |O          |\n",
      "|bleeding                |B-problem   |B-problem  |\n",
      "|vessel                  |I-problem   |I-problem  |\n",
      "|sigmoidoscopy           |B-test      |B-test     |\n",
      "|colonoscopy             |B-test      |B-test     |\n",
      "|history                 |O           |O          |\n",
      "|of                      |O           |O          |\n",
      "|present                 |O           |O          |\n",
      "|illness                 |O           |O          |\n",
      "|:                       |O           |O          |\n",
      "|hpi                     |O           |O          |\n",
      "|:                       |O           |O          |\n",
      "|pt                      |O           |O          |\n",
      "|is                      |O           |O          |\n",
      "|a                       |O           |O          |\n",
      "|71                      |O           |O          |\n",
      "+------------------------+------------+-----------+\n",
      "only showing top 70 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.select(F.explode(F.arrays_zip('token.result','label.result','ner.result')).alias(\"cols\")) \\\n",
    "           .select(F.expr(\"cols['0']\").alias(\"token\"),\n",
    "                   F.expr(\"cols['1']\").alias(\"ground_truth\"),\n",
    "                   F.expr(\"cols['2']\").alias(\"prediction\")).show(70,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WORD_EMBEDDINGS_MODEL_ce73dc8c7bc4, NerDLModel_ba52c8d1f745]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_model.stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save NERDL model\n",
    "ner_model.stages[1].write().overwrite().save('./models/NER_DL_trained_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save Word Embeddings model\n",
    "ner_model.stages[0].write().overwrite().save('./models/WordEmbeddingsModel_BioVec_200d_20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop spark session\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
