{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "import sparknlp\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp.common import *\n",
    "from sparknlp.base import *\n",
    "from sparknlp.training import CoNLL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = sparknlp.start()\n",
    "#spark = sparknlp.start(gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark NLP version:  2.4.3\n",
      "Apache Spark version:  2.4.5\n"
     ]
    }
   ],
   "source": [
    "print(\"Spark NLP version: \", sparknlp.version())\n",
    "print(\"Apache Spark version: \", spark.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read CoNLL train file\n",
    "training_data = CoNLL().readDataset(spark, '/home/aminmoradi/sddm_project/CoNLL_parser/conll.train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|            text|            document|            sentence|               token|                 pos|               label|\n",
      "+----------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|admission date :|[[document, 0, 15...|[[document, 0, 15...|[[token, 0, 8, ad...|[[pos, 0, 8, NN, ...|[[named_entity, 0...|\n",
      "|      2018-10-25|[[document, 0, 9,...|[[document, 0, 9,...|[[token, 0, 9, 20...|[[pos, 0, 9, NN, ...|[[named_entity, 0...|\n",
      "|discharge date :|[[document, 0, 15...|[[document, 0, 15...|[[token, 0, 8, di...|[[pos, 0, 8, NN, ...|[[named_entity, 0...|\n",
      "|      2018-10-31|[[document, 0, 9,...|[[document, 0, 9,...|[[token, 0, 9, 20...|[[pos, 0, 9, NN, ...|[[named_entity, 0...|\n",
      "| date of birth :|[[document, 0, 14...|[[document, 0, 14...|[[token, 0, 3, da...|[[pos, 0, 3, NN, ...|[[named_entity, 0...|\n",
      "+----------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16311"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read CoNLL test file\n",
    "test_data = CoNLL().readDataset(spark, '/home/aminmoradi/sddm_project/CoNLL_parser/conll.test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27568"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glove_100d download started this may take some time.\n",
      "Approximate size to download 145.3 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "GloVe_embeddings = WordEmbeddingsModel.pretrained()\\\n",
    "    .setInputCols([\"sentence\", \"token\"])\\\n",
    "    .setOutputCol(\"glove\")\\\n",
    "    .setCaseSensitive(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_glove = GloVe_embeddings.transform(test_data)\n",
    "test_data_glove.write.parquet(\"test_withGloveEmbeds.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "nerTagger = NerDLApproach()\\\n",
    "  .setInputCols([\"sentence\", \"token\", \"glove\"])\\\n",
    "  .setLabelColumn(\"label\")\\\n",
    "  .setOutputCol(\"ner\")\\\n",
    "  .setMaxEpochs(10)\\\n",
    "  .setLr(0.001)\\\n",
    "  .setPo(0.005)\\\n",
    "  .setBatchSize(8)\\\n",
    "  .setRandomSeed(0)\\\n",
    "  .setVerbose(2)\\\n",
    "  .setValidationSplit(0.25)\\\n",
    "  .setEvaluationLogExtended(True) \\\n",
    "  .setEnableOutputLogs(True)\\\n",
    "  .setIncludeConfidence(True)\\\n",
    "  .setTestDataset(\"test_withGloveEmbeds.parquet\")\n",
    "\n",
    "\n",
    "pipeline = Pipeline( stages = [\n",
    "                GloVe_embeddings,\n",
    "                nerTagger\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_model = pipeline.fit(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|            text|            document|            sentence|               token|                 pos|               label|               glove|                 ner|\n",
      "+----------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|admission date :|[[document, 0, 15...|[[document, 0, 15...|[[token, 0, 8, ad...|[[pos, 0, 8, NN, ...|[[named_entity, 0...|[[word_embeddings...|[[named_entity, 0...|\n",
      "|      2012-10-31|[[document, 0, 9,...|[[document, 0, 9,...|[[token, 0, 9, 20...|[[pos, 0, 9, NN, ...|[[named_entity, 0...|[[word_embeddings...|[[named_entity, 0...|\n",
      "|discharge date :|[[document, 0, 15...|[[document, 0, 15...|[[token, 0, 8, di...|[[pos, 0, 8, NN, ...|[[named_entity, 0...|[[word_embeddings...|[[named_entity, 0...|\n",
      "+----------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = ner_model.transform(test_data)\n",
    "predictions.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+------------+-----------+\n",
      "|token                   |ground_truth|prediction |\n",
      "+------------------------+------------+-----------+\n",
      "|admission               |O           |O          |\n",
      "|date                    |O           |O          |\n",
      "|:                       |O           |O          |\n",
      "|2012-10-31              |O           |O          |\n",
      "|discharge               |O           |O          |\n",
      "|date                    |O           |O          |\n",
      "|:                       |O           |O          |\n",
      "|2012-11-07              |O           |O          |\n",
      "|date                    |O           |O          |\n",
      "|of                      |O           |O          |\n",
      "|birth                   |O           |O          |\n",
      "|:                       |O           |O          |\n",
      "|1941-03-23              |O           |O          |\n",
      "|sex                     |O           |O          |\n",
      "|:                       |O           |O          |\n",
      "|m                       |O           |O          |\n",
      "|service                 |O           |O          |\n",
      "|:                       |O           |O          |\n",
      "|medicine                |O           |B-treatment|\n",
      "|allergies               |O           |O          |\n",
      "|:                       |O           |O          |\n",
      "|nsaids/anti-inflammatory|B-treatment |B-treatment|\n",
      "|classifier              |I-treatment |I-treatment|\n",
      "|/                       |O           |O          |\n",
      "|vancomycin              |B-treatment |B-treatment|\n",
      "|attending               |O           |O          |\n",
      "|:                       |O           |O          |\n",
      "|kristie                 |O           |O          |\n",
      "|r                       |O           |O          |\n",
      "|hamby                   |O           |O          |\n",
      "|,                       |O           |O          |\n",
      "|md                      |O           |O          |\n",
      "|chief                   |O           |O          |\n",
      "|complaint               |O           |O          |\n",
      "|:                       |O           |O          |\n",
      "|cc                      |O           |O          |\n",
      "|:                       |O           |O          |\n",
      "|antonio                 |O           |O          |\n",
      "|m                       |O           |O          |\n",
      "|z                       |O           |O          |\n",
      "|eddings                 |O           |O          |\n",
      "|,                       |O           |O          |\n",
      "|md                      |O           |O          |\n",
      "|major                   |O           |O          |\n",
      "|surgical                |O           |O          |\n",
      "|or                      |O           |O          |\n",
      "|invasive                |O           |O          |\n",
      "|procedure               |O           |O          |\n",
      "|:                       |O           |O          |\n",
      "|mesenteric              |B-test      |B-test     |\n",
      "|angiograpm              |I-test      |I-test     |\n",
      "|w/                      |O           |O          |\n",
      "|coil                    |B-treatment |B-treatment|\n",
      "|embolization            |I-treatment |I-treatment|\n",
      "|of                      |O           |O          |\n",
      "|bleeding                |B-problem   |B-problem  |\n",
      "|vessel                  |I-problem   |O          |\n",
      "|sigmoidoscopy           |B-test      |B-treatment|\n",
      "|colonoscopy             |B-test      |B-test     |\n",
      "|history                 |O           |O          |\n",
      "|of                      |O           |O          |\n",
      "|present                 |O           |O          |\n",
      "|illness                 |O           |O          |\n",
      "|:                       |O           |O          |\n",
      "|hpi                     |O           |O          |\n",
      "|:                       |O           |O          |\n",
      "|pt                      |O           |O          |\n",
      "|is                      |O           |O          |\n",
      "|a                       |O           |O          |\n",
      "|71                      |O           |O          |\n",
      "|y/o                     |O           |O          |\n",
      "|male                    |O           |O          |\n",
      "|with                    |O           |O          |\n",
      "|h/o                     |B-problem   |O          |\n",
      "|dm2                     |O           |B-problem  |\n",
      "|,                       |B-problem   |O          |\n",
      "|cad                     |O           |B-problem  |\n",
      "|s/p                     |B-treatment |O          |\n",
      "|cabg                    |O           |B-treatment|\n",
      "|,                       |B-problem   |O          |\n",
      "|dvt/pe                  |O           |B-treatment|\n",
      "|on                      |B-treatment |O          |\n",
      "|long                    |I-treatment |B-treatment|\n",
      "|term                    |I-treatment |I-treatment|\n",
      "|anti-coagulation        |O           |I-treatment|\n",
      "|,                       |B-problem   |O          |\n",
      "|ulcerative              |I-problem   |B-problem  |\n",
      "|colitis                 |O           |I-problem  |\n",
      "|on                      |B-treatment |O          |\n",
      "|asacol                  |O           |B-treatment|\n",
      "|presents                |O           |O          |\n",
      "|with                    |B-problem   |O          |\n",
      "|brbpr                   |O           |B-treatment|\n",
      "|starting                |O           |O          |\n",
      "|at                      |O           |O          |\n",
      "|9am                     |O           |O          |\n",
      "|of                      |O           |O          |\n",
      "|the                     |O           |O          |\n",
      "|morning                 |O           |O          |\n",
      "|of                      |O           |O          |\n",
      "+------------------------+------------+-----------+\n",
      "only showing top 100 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.select(F.explode(F.arrays_zip('token.result','label.result','ner.result')).alias(\"cols\")) \\\n",
    "        .select(F.expr(\"cols['0']\").alias(\"token\"),\n",
    "            F.expr(\"cols['1']\").alias(\"ground_truth\"),\n",
    "            F.expr(\"cols['2']\").alias(\"prediction\")).show(100,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WORD_EMBEDDINGS_MODEL_48cffc8b9a76, NerDLModel_38add6240ea3]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_model.stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_model.stages[1].write().overwrite().save('NER_DL_GloVe_100d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
